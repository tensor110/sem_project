{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "668d2285-a820-4ced-8363-dc9470d135ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5bb12d5-4266-4fce-9ead-8a5f48ad8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5993eaea-1c0a-4e7f-b1f2-68303c2e9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NewsCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Adaptive pooling makes output fixed size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = self.adaptive_pool(x)  # Output becomes (batch, 128, 1, 1)\n",
    "        x = x.view(x.size(0), -1)  # Now (batch, 128)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a4a64dc-29b2-409d-b4a7-84f3afc7928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Preprocessing (From PDF Step 1)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4df316de-b65a-4c3e-ab6b-707f2da16e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"dataset/train\",\n",
    "    transform=transform,\n",
    "    is_valid_file=lambda x: x.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec3382dd-74e0-4d9e-8416-02e84ad9c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"dataset/test\",\n",
    "    transform=transform,\n",
    "    is_valid_file=lambda x: x.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1385e7ad-ef30-4316-a59f-1b90fb717d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "164322d4-67b2-4930-b1a0-e040626e4798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint['model_state_dict']['fc2.weight'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "527608a5-2a2b-4cc5-ac1a-9b80a9994e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained CNN (Feature Extraction)\n",
    "# model = models.resnet50(weights=None)\n",
    "# model = NewsCNN(num_classes=2)\n",
    "model = NewsCNN(num_classes=len(train_dataset.classes)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce214a5f-0083-49ae-8c64-270ab8d0e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace final layer (Softmax Classification Layer - Equation 4 in PDF)\n",
    "# num_classes = 2  # sports and disaster\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4402fad3-6e26-405c-b9c4-183f0ac250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1eff65d9-8798-474d-950c-7b006af3e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.6940\n",
      "Epoch [2/15], Loss: 0.6935\n",
      "Epoch [3/15], Loss: 0.6929\n",
      "Epoch [4/15], Loss: 0.6924\n",
      "Epoch [5/15], Loss: 0.6921\n",
      "Epoch [6/15], Loss: 0.6917\n",
      "Epoch [7/15], Loss: 0.6915\n",
      "Epoch [8/15], Loss: 0.6912\n",
      "Epoch [9/15], Loss: 0.6910\n",
      "Epoch [10/15], Loss: 0.6907\n",
      "Epoch [11/15], Loss: 0.6904\n",
      "Epoch [12/15], Loss: 0.6902\n",
      "Epoch [13/15], Loss: 0.6898\n",
      "Epoch [14/15], Loss: 0.6896\n",
      "Epoch [15/15], Loss: 0.6892\n",
      "Training complete. Model saved.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"news_model.pth\")\n",
    "print(\"Training complete. Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89dbfab9-42af-4c46-99b0-b1092c114d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disaster', 'politics']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f692dda-531f-4c00-8148-2ace3f102397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 8, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(train_dataset.targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc93011c-a061-4904-b996-6f6d58f76051",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': train_dataset.classes\n",
    "}, \"news_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c29ae-5799-423e-bf34-ac63117cc585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
